
import { GoogleGenAI, GenerateContentResponse, Modality, Type, Operation, GenerateVideosResponse } from "@google/genai";

const getAI = () => new GoogleGenAI({ apiKey: process.env.API_KEY });

// For Image Generation (Imagen)
export const generateImage = async (prompt: string, numberOfImages: number, aspectRatio: string): Promise<string[]> => {
    const ai = getAI();
    const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt,
        config: {
            numberOfImages,
            outputMimeType: 'image/png',
            aspectRatio: aspectRatio as any,
        },
    });

    return response.generatedImages.map(img => img.image.imageBytes);
};

// For Image Editing/Analysis (Gemini Flash Image)
export const editImage = async (prompt: string, sourceImage: { data: string; mimeType: string }): Promise<string> => {
    const ai = getAI();
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: {
            parts: [
                { inlineData: { data: sourceImage.data, mimeType: sourceImage.mimeType } },
                { text: prompt },
            ],
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });
    const part = response.candidates?.[0]?.content?.parts.find(p => p.inlineData);
    if (part?.inlineData) {
        return part.inlineData.data;
    }
    throw new Error("No image was generated by the model.");
};

export const analyzeImage = async (prompt: string, sourceImage: { data: string; mimeType: string }): Promise<string> => {
    const ai = getAI();
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: {
            parts: [
                { inlineData: { data: sourceImage.data, mimeType: sourceImage.mimeType } },
                { text: prompt },
            ],
        }
    });
    return response.text;
};

// For Text-based tasks
export const translateText = async (text: string, sourceLang: string, targetLang: string): Promise<string> => {
    const ai = getAI();
    const prompt = `Translate the following text from ${sourceLang === 'auto' ? 'the auto-detected language' : sourceLang} to ${targetLang}. Only return the translated text, without any additional explanation or formatting.\n\nText: "${text}"`;
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: prompt,
    });
    return response.text;
};

export const textToSpeech = async (text: string): Promise<string> => {
    const ai = getAI();
    const response = await ai.models.generateContent({
        model: "gemini-2.5-flash-preview-tts",
        contents: [{ parts: [{ text: `Say: ${text}` }] }],
        config: {
            responseModalities: [Modality.AUDIO],
            speechConfig: {
                voiceConfig: {
                    prebuiltVoiceConfig: { voiceName: 'Kore' },
                },
            },
        },
    });
    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (base64Audio) {
        return base64Audio;
    }
    throw new Error("Failed to generate speech from text.");
};

export const summarizeText = async (text: string): Promise<GenerateContentResponse> => {
    const ai = getAI();
    return ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: `Summarize the following text:\n\n${text}`,
    });
};

export const modifyText = async (text: string, instruction: string): Promise<GenerateContentResponse> => {
    const ai = getAI();
    return ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: `Given the following text, please modify it based on this instruction: "${instruction}".\n\nText:\n${text}`,
    });
};

export const optimizeText = async (text: string, options: any): Promise<GenerateContentResponse> => {
    const ai = getAI();
    const { creativity, readability, formality, tone, intent } = options;
    const prompt = `
        Original Text: "${text}"

        Task: Optimize the text based on the following parameters.
        - Intent: ${intent}
        - Creativity Level (0=strict, 100=imaginative): ${creativity}
        - Target Readability (0=simple, 100=complex): ${readability}
        - Formality: ${formality}
        - Tone: ${tone}

        Return only the optimized text.
    `;
    return ai.models.generateContent({ model: 'gemini-2.5-pro', contents: prompt });
};


// For Chat Widget suggestions
export const generateChatSuggestions = async (context: string): Promise<GenerateContentResponse> => {
    const ai = getAI();
    return ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: `Based on the user's current context in the app, generate 3 concise, relevant, and helpful suggestions for what they might ask the AI assistant. Context: "${context}".`,
        config: {
            responseMimeType: "application/json",
            responseSchema: {
                type: Type.ARRAY,
                items: { type: Type.STRING },
            },
        }
    });
};

// For Video
// FIX: The Operation type requires a generic argument. For video operations, it is GenerateVideosResponse.
export const generateVideo = async (prompt: string, image: { data: string, mimeType: string } | null, config: any): Promise<Operation<GenerateVideosResponse>> => {
    const ai = getAI(); // Per guidelines, create new instance for Veo
    const payload: any = {
        model: 'veo-3.1-fast-generate-preview',
        prompt,
        config: {
            numberOfVideos: 1,
            resolution: config.resolution,
            aspectRatio: config.aspectRatio,
        },
    };
    if (image) {
        payload.image = {
            imageBytes: image.data,
            mimeType: image.mimeType,
        };
    }
    return ai.models.generateVideos(payload);
};

// FIX: The Operation type requires a generic argument. For video operations, it is GenerateVideosResponse.
export const checkVideoOperation = async (operation: Operation<GenerateVideosResponse>): Promise<Operation<GenerateVideosResponse>> => {
    const ai = getAI(); // Per guidelines, create new instance for Veo
    return ai.operations.getVideosOperation({ operation });
};
